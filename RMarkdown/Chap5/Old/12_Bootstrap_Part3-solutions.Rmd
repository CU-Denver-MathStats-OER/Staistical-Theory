---
output:
  html_document: default
---
# Bootstrap Distributions Part 3
### March 24, 2021

**Load required packages first**
```{r, message=FALSE}
library(resampledata)
```

## Section 5.6: Bias

* An estimator $\hat{\theta}$ is **biased** if on average it tends to be too high or too low relative to the true value of $\theta$. The bias of an estimator is

$$ 
\mbox{Bias}\lbrack \hat{\theta} \rbrack = \mbox{E} \lbrack \hat{\theta} \rbrack - \theta. 
$$

* The bootstrap estimate of bias is
 
$$
\mbox{Bias}_{\rm{boot}} \lbrack \hat{\theta}^{\ast} \rbrack =  \mbox{E} \lbrack \hat{\theta}^{\ast} \rbrack - \hat{\theta}.
$$

+ $\mbox{E} \lbrack \hat{\theta}^{\ast} \rbrack$ denotes the center of the bootstrap distribution.

+ $\hat{\theta}$ denotes the sample statistic.

* An estimator is **unbiased if the bias is zero**.

### Question 2

2. Calculate the bootstrap estimate of bias in the previous Verizon example.

```{r}
Time.ILEC <- subset(Verizon, select = Time, Group == "ILEC", drop =T)
Time.CLEC <- subset(Verizon, select = Time, Group == "CLEC", drop =T)
original.ratio <- mean(Time.ILEC)/mean(Time.CLEC) #theta hat -estimator

N <- 10^4
time.ratio.mean <- numeric(N) #bootstrap distribution
for (i in 1:N)
{
  ILEC.sample <- sample(Time.ILEC, 1664, replace = TRUE)
  CLEC.sample <- sample(Time.CLEC, 23, replace = TRUE)
  time.ratio.mean[i] <- mean(ILEC.sample)/mean(CLEC.sample)
}

mean2.boot <- mean(time.ratio.mean) #center of the bootstrap distribution E(theta-hat*)
mean2.boot - original.ratio
```

We have $\mbox{E} \lbrack \hat{\theta}^{\ast} \rbrack =$ `r mean2.boot`

We have $\hat{\theta} =$ `r original.ratio`

The bias is therefore $\mbox{Bias}_{\rm boot} \lbrack \hat{\theta}^{\ast} \rbrack =$ `r mean2.boot -  original.ratio`. 

Visually, the estimator is marked in red (the ratio of the our original sample means). The estimate for the expected value of the estimator is given by the center of the bootstrap distribution which is marked in blue. The bias is the distance between these two lines.

```{r}
hist(time.ratio.mean)
abline(v = original.ratio, col = "red", lwd = 2, lty = 2)
abline(v = mean2.boot, col = "blue", lwd = 2, lty = 2)
```

### Rule of Thumb for Bias

* We can measure how extreme is the bias of an estimator using the ratio

$$
\frac{\mbox{Bias}}{\mbox{SE}} \approx  \frac{\mbox{Bootstrap Bias}}{\mbox{Bootstrap SE}}.
$$
* **Rule of Thumb:** If the ratio bias/SE exceeds $\pm 0.02$, then the bias is large enough to have a substantial effect on the accuracy of the estimate.

To check:
(1) Compute the bootstrap estimate for the bias of the estimator
(2) Calculate the bootstrap estimate for the standard error (sd of bootstrap dist)
(3) Take the ratio: bias/SE

### Question 3 

```{r}
125.229 - 125.320
```

In the arsenic example  we used a bootstrap distribution to estimate the mean arsenic level (in ppb) present in groundwater in Bangladesh. The mean of the original sample is $\bar{x} = 125.320$. A mean of a bootstrap distribution is $125.229$. Then the bootstrap standard error is 17.9. **Which bias is more extreme, the bias in the arsenic or Verizon example?**

* For the arsenic example we have Bias/SE is 

```{r} 
(125.229-125.320)/17.9
```

This falls below the threshold of 0.02. So the bias in the arsenic example is not very significant.

* For the Verizon example we have Bias/SE is 

```{r}
(mean(time.ratio.mean) - original.ratio)/sd(time.ratio.mean)
```

This is above the threshold of 0.02, so the bias of this estimator is severe enough to affect the accuracy.

## Sections 5.7-5.9: Implementation and Accuracy

4. If we had a sample {10,  20 , 18}, how many possible bootstrap samples are there?

10, 10, 10  
10, 20, 20  
10, 18, 18  
10, 20, 18  
20, 20, 20  
20, 10, 10  
20, 18, 18  
18, 18, 18  
18, 10, 10  
18, 20, 20  

How many possible bootstrap resamples can we generate from a sample of 3 values?


In the example above, we have three possible values to pick for each of the three observations in the bootstrap sample. So you might think there would be a total of $3^3=27$ possible bootstrap samples. But there are only 10. This is because the bootstrap sample {10,20,20} is the same as {20,10,20} which is the same as {20,20,10}. So we need to be careful to avoid double and triple counting the same sample multiple times.

In general, an original sample of size n has $n^n$ possible bootstrap samples if we ignore the order. Taking into account different ordering still gives the same sample, we get have a total of:

$$
\left( \begin{array}{c}  2n-1 \\ n  \end{array} \right)
$$

Thus, for the example above we have $n=3$, so we have a total of 10 distinct bootstrap samples.
 
```{r}
choose(2*3-1,3)
```


In the Verizon example, there are at most $1664^{1664} \cdot 23^{23}$ different bootstrap samples (if we ignore ordering at first). If there are duplicate values in the sample(s), then it gets even more tricky to avoid repeats.

* We have not been ensuring we generate all possible bootstrap samples while avoiding repeats.  
* We have used \textbf{Monte Carlo sampling} which gives an estimate of the theoretical bootstrap distribution.  
* The larger the number of bootstrap samples, the better the estimate. As a rule, $N=10^4$ bootstrap samples or more is sufficient.  


{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: '4.1: Maximum Likelihood Estimation'\n",
        "#author: 'Adam Spiegler, University of Colorado Denver'\n",
        "execute:\n",
        "  eval: false\n",
        "output:\n",
        "  html_document:\n",
        "#    toc: yes\n",
        "#    toc_depth: 1\n",
        "#    theme: cerulean\n",
        "#jupyter:\n",
        "#  kernelspec:\n",
        "#    display_name: R\n",
        "#    language: R\n",
        "#    name: ir\n",
        "#output:\n",
        "#    ipynbdocument::ipynb_document\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/CU-Denver-MathStats-OER/Statistical-Theory/blob/main/Chap4/13-Estimation-MLE.ipynb) <nbsp>\n",
        "\n",
        "![Credit: [Arrows in the target](https://creazilla.com/nodes/60165-arrows-in-the-target-clipart), Public Domain](https://creazilla-store.fra1.digitaloceanspaces.com/cliparts/60165/arrows-in-the-target-clipart-md.png){fig-align=\"left\" width=30% fig-alt=\"Arrows Hitting a Target\"} <nbsp>\n",
        "\n",
        "In Chapter 3, we explored properties of sample statistics picked from a population with a known distribution.\n",
        "\n",
        "  - We analyzed the [distribution of sample means](10-Sampling-Dist-Mean.qmd) picked from normal and exponential distributions.\n",
        "  - We analyzed the [distribution of sample proportions](11-Sampling-Dist-Prop.qmd) independently pick from a binomial population.\n",
        "  - Sampling distributions allowed us to predict how likely we are to pick certain sample statistics when the population is fixed and known.\n",
        "\n",
        "However, statistical inference is applied in situations where <span style=\"color:dodgerblue\">**properties of the populations are unknown**</span>. A typical workflow for statistical inference is:\n",
        "\n",
        "1. Pick one (not thousands) random sample from a population with unknown characteristics.\n",
        "2. Calculate sample statistic(s) to describe the sample.\n",
        "3. Based on the characteristics of the sample, make predictions/estimates for the unknown population characteristics.\n",
        "\n",
        "In this chapter, we explore two powerful estimation techniques, maximum likelihood estimation and the method of moments. We will investigate how well our estimators perform using general properties of estimators such as bias, efficiency, and mean square error.\n",
        "\n",
        "# Case Study: Slot Machine Jackpots"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "![Credit: [Casino Game Room Slot Machines](https://pixabay.com/photos/casino-game-room-slot-machines-3491252/) by [Bru-nO](https://pixabay.com/users/bru-no-1161770/), Open License](https://cdn.pixabay.com/photo/2018/06/22/17/54/casino-3491252_1280.jpg){fig-align=\"left\" width=50% fig-alt=\"Light Rail Train in Denver\"} <nbsp>\n",
        "\n",
        "\n",
        "A strategic gambler believes they have identified a faulty slot machine which pays out significantly more money than the other slot machines. She and her friends watch the machine 24 hours a day for 7 days and observed the slot machine paid out the \\$$1,\\!000,\\!000$ jackpot prize 10 times during the week. How can she figure out whether the machine is faulty or whether the number of jackpot prizes are within reason?\n",
        "\n",
        "\n",
        "## ggg Question 1 zzz\n",
        "\n",
        "----\n",
        "\n",
        "They decide to compare the performance of the suspect slot machine to other slot machines. They pick a random sample of $n=4$ other slot machines and record how many jackpot prizes each machine pays over a one week time frame. Let random variable $X$ denote the number of jackpots a randomly selected slot machine pays out in week. What distribution do you think best models $X$? Give a corresponding formula for the probability mass function of $X$.\n",
        "\n",
        "- *Hint: Should we use a discrete or continuous random variable?*\n",
        "- *Hint: See either [appendix of common discrete random variables](07-Common-Discrete-RandVar.qmd#sec-append) or [appendix of common continuous random variables](08-Common-Continuous-Distributions.qmd#sec-append) for additional help.*\n",
        "\n",
        "\n",
        "### ggg Solution to Question 1 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "## ggg Collecting Data zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We will simulate collecting a data sample.\n",
        "\n",
        "- Run the code cell below to \"secretly\" generate a population mean that we store in `true.mean`. \n",
        "- The command `set.seed(827)` will seed the randomization so we all have the same population mean.\n",
        "- Do not print the output to screen. Keep `true.mean` secret for now!\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "# set randomization for seeding population mean\n",
        "set.seed(827)  \n",
        "\n",
        "# pick a population mean that will be fixed but unknown to us\n",
        "true.mean <- sample(3:8, size=1)\n",
        "```\n",
        "\n",
        "\n",
        "Next, we generate a sample size $n=4$.\n",
        "\n",
        "- Run the code cell below to generate your random sample.\n",
        "- Each observation $x_i$ in the vector `x` corresponds to the number of jackpots a randomly selected slot machine paid out in one week.\n",
        "- The command `set.seed(612)` will seed the randomization so my sample `x` remains fixed.\n",
        "  - You can delete the command `set.seed(612)` to generate a different random sample picked from the same population.\n",
        "  - Then you can compare the estimate obtained from your sample with the estimate based on the sample generated below.\n",
        "- Inspect the values in your sample after running.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "set.seed(612)\n",
        "\n",
        "x <- rpois(4, true.mean)\n",
        "x\n",
        "```\n",
        "\n",
        "\n",
        "- The sample generated by `set.seed(612)` is\n",
        "\n",
        "$$x_1=9 \\ ,\\  x_2=8\\ ,\\  x_3=6 \\ , \\ x_4=5.$$\n",
        "\n",
        "## ggg Question 2 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the probability mass function from [Question 1] and your sample generated by the code cell above stored in `x`, what is the probability of picking the random sample $x_1$, $x_2$, $x_3$, $x_4$ stored in `x`? Your answer will be a formula that depends on the parameter $\\lambda$.\n",
        "\n",
        "### ggg Solution to Question 2 zzz\n",
        "\n",
        "----\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# ggg What Is the Probability of Picking Our Random Sample? zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We motivate maximum likelihood estimation with the following question:\n",
        "\n",
        "> <span style=\"color:dodgerblue\">What is the most likely value for the unknown parameter $\\theta$ given we know a random sample of values $x_1, x_2, \\ldots x_n$?</span>\n",
        "\n",
        "The <span style=\"color:dodgerblue\">**likelihood function**</span> \n",
        "$$\\color{dodgerblue}{L(\\theta)= L( \\theta \\mid x_1, x_2, \\ldots x_n)}$$ \n",
        "gives the likelihood of the parameter $\\theta$ given the observed sample data.  A <span style=\"color:dodgerblue\">**maximum likelihood estimate (MLE)**</span>, denoted $\\color{dodgerblue}{\\mathbf{\\hat{\\theta}_{\\rm MLE}}}$, is the value of $\\theta$ that gives the maximum value of the likelihood function $L(\\theta)$.\n",
        "\n",
        "\n",
        ":::{.callout-note}\n",
        "In statistics, we typically <span style=\"color:dodgerblue\">**use Greek letters to denote population parameters**</span>, and <span style=\"color:dodgerblue\">**we use \"hat\" notation to indicate an estimator**</span> for the value of a population parameter.\n",
        "\n",
        "- The notation $\\theta$ is the generic notation typically used to represent a parameter.\n",
        "- The notation $\\hat{\\theta}$ denotes an estimator for  $\\theta$.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## ggg Question 3 zzz\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the value of $\\lambda$ that maximizes the likelihood function from [Question 2].\n",
        "\n",
        ":::{.callout-tip}\n",
        "Recall from calculus that global maxima occur at end points or critical points where $\\frac{d L}{d \\lambda} = 0$ or is undefined.\n",
        ":::\n",
        "\n",
        "### ggg Solution to Question 3 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "### ggg Plotting the Likelihood Function for Question 3 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given the random sample $x_1=9,  x_2=8, x_3=6, x_4=5$, the resulting likelihood derived in [Question 2] is\n",
        "\n",
        "$$L({\\color{tomato}\\lambda}) = \\frac{{\\color{tomato}\\lambda}^{28} e^{-4{\\color{tomato}\\lambda}}}{(9!)(8!)(6!)(5!)}.$$\n",
        "\n",
        "In [Question 3], we find the value of $\\lambda$ that maximizes the likelihood function $L(\\lambda)$ using optimization methods from calculus. It is always a good idea to check our work. If we have access to technology, we can plot the likelihood function and identify the approximate value of $\\lambda$ that gives the maximum value of $L(\\lambda)$.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "lam <- seq(3, 11, 0.1)  # values of lambda on x-axis\n",
        "like.est <- lam^(sum(x)) * exp(-4*lam)/prod(factorial(x))  # values of L(lambda)\n",
        "\n",
        "plot(lam, like.est,  # plot lam and likelihood on x and y axes\n",
        "     type = \"l\",  # connect plotted points with a curve\n",
        "     ylab = \"L(lambda)\",  # y-axis label\n",
        "     xlab = \"lambda\",  # x-axis label\n",
        "     main = \"Plot of Likelihood Function\")  # main label\n",
        "\n",
        "points(x = 7, y = 0.0002515952, cex = 2, pch = 20, col = \"tomato\")  # point at max\n",
        "\n",
        "axis(1, at=c(7), col.axis = \"tomato\", pos=0)  # marking MLE estimate\n",
        "abline(v = 7, col = \"tomato\", lwd = 2, lty = 2)  # marking MLE estimate\n",
        "```\n",
        "\n",
        "## ggg Revealing the Actual Value of $\\lambda$ zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We picked a value for $\\lambda$ and stored it in `true.mean`. We have not revealed what the actual value of $\\lambda$ is. Run the code cell below to see that actual value of $\\lambda$, and compare your answer for $\\hat{\\lambda}_{\\rm{MLE}}$ in [Question 3] with the actual value of $\\lambda$.\n",
        "\n",
        "\n",
        "```{r}\n",
        "true.mean\n",
        "```\n",
        "\n",
        "\n",
        "# ggg A Formula for the Likelihood Function zzz\n",
        "\n",
        "\n",
        "Let $f(x; \\theta)$ denote the pdf of a random variable $X$ with associated parameter $\\theta$. Suppose\n",
        "$X_1, X_2, \\ldots , X_n$ are random samples from this distribution, and $x_1, x_2, \\ldots , x_n$ are the\n",
        "corresponding observed values.\n",
        "\n",
        "$$\\color{dodgerblue}{\\boxed{L(\\theta \\mid x_1, x_2, \\ldots , x_n) = f(x_1; \\theta) f(x_2; \\theta) \\ldots f(x_n; \\theta) = \\prod_{i=1}^n f(x_i; \\theta).}}$$\n",
        "\n",
        ":::{.callout-important}\n",
        "In the formula for the likelihood function, the values $x_1, x_2, \\ldots x_n$ are fixed values, and the parameter $\\theta$ is the variable in the likelihood function. We consider what happens to the value of the $L(\\theta)$ when we vary the value of $\\theta$. The MLE $\\hat{\\theta}_{\\rm{MLE}}$ is the value of $\\theta$ that gives the maximum value of $L(\\theta)$.\n",
        ":::\n",
        "\n",
        "\n",
        "# ggg Defining the Likelihood Function in R zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In [Question 2] we derived an expression for the likelihood function $L(\\lambda)$ given the random sample of $n=4$ values we picked from $X \\sim \\mbox{Pois}( \\lambda)$ and stored in the vector `x`. Recall Poisson distributions have pmf\n",
        "\n",
        "$$f(x; \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\qquad \\mbox{for } x = 0, 1, 2, \\ldots .$$ \n",
        "\n",
        "If we pick a sample of $n=4$ values we denote $X_1 = x_1$, $X_2 = x_2$, $X_3 = x_3$, and $X_4 = x_4$, then the likelihood function is\n",
        "\n",
        "$$L(\\lambda) = L(\\theta \\mid x_1, x_2, \\ldots , x_n) = \\left( \\frac{\\lambda^{x_1} e^{-\\lambda}}{x_1!} \\right) \\left( \\frac{\\lambda^{x_2} e^{-\\lambda}}{x_2!} \\right) \\left( \\frac{\\lambda^{x_3} e^{-\\lambda}}{x_3!} \\right) \\left( \\frac{\\lambda^{x_4} e^{-\\lambda}}{x_4!} \\right).$$\n",
        "\n",
        "We will use the random sample generated by the code cell below. Note `x` is a vector consisting of values `x[1]` $=9$, `x[2]` $=8$, `x[3]` $=6$, and `x[4]` $=5$.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "set.seed(612)\n",
        "\n",
        "x <- rpois(4, true.mean)\n",
        "x\n",
        "```\n",
        "\n",
        "## ggg Defining the Likelihood Function as Product zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "In the code cell below, we input the likelihood function. \n",
        "\n",
        "- To define a symbolic function, we use the command `function(lam) [expr]`.\n",
        "  - We use `lam` to denote our variable, $\\lambda$.\n",
        "  - We enter an expression in place of `[expr]`. \n",
        "- For `[expr]`, we enter the product of the four expressions we get from the pmf for the Poisson distribution.\n",
        "- The function is stored as the object `like`.\n",
        "- To evaluate the function at $\\lambda = 7$, we can use the command `like(7)`.\n",
        "\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "like <- function(lam) lam^x[1] * exp(-lam)/factorial(x[1]) *\n",
        "  lam^x[2] * exp(-lam)/factorial(x[2]) * \n",
        "  lam^x[3] * exp(-lam)/factorial(x[3]) *\n",
        "  lam^x[4] * exp(-lam)/factorial(x[4])\n",
        "\n",
        "like(7)\n",
        "```\n",
        "\n",
        "\n",
        "## ggg Improving the Code for a Likelihood Function zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code cell above can be streamlined. If we have a sample size $n=100$ instead of $n=4$, we would not want to code the likelihood as we did in the previous code cell. We can streamline the process by making use of the structure of a likelihood function:\n",
        "\n",
        "- Each term in the product uses the same formula for the pmf.\n",
        "- The likelihood function is a product of all the pmf's.\n",
        "\n",
        "In the slot machine example, we have $X \\sim \\mbox{Pois}(\\lambda)$ and a sample $x_1=9$, $x_2=8$ , $x_3=6$, and $x_4=5$. The vectors `x` and `pmf` are therefore\n",
        "\n",
        "$$ x = (9, 8, 6, 5) \\quad \\mbox{and} \\quad \\mbox{pmf} = \\left( \\frac{\\lambda^{9} e^{-\\lambda}}{9!} , \\frac{\\lambda^{8} e^{-\\lambda}}{8!} , \\frac{\\lambda^{6} e^{-\\lambda}}{6!} , \\frac{\\lambda^{5} e^{-\\lambda}}{5!} \\right).$$ \n",
        "\n",
        "The likelihood function `like` is the product of the entries in the vector `pmf`, and the resulting product is a function of $\\lambda$. We can substitute different values for the parameter $\\lambda$ into the function `like` and compute different values of the likelihood function.\n",
        "\n",
        "- Run the code cell below to compute the likelihood, given the sample `x`, that $\\lambda = 7$.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "like <- function(lam){\n",
        "  pmf <- lam^x * exp(-lam)/factorial(x)\n",
        "  prod(pmf)\n",
        "}\n",
        "\n",
        "like(7)\n",
        "```\n",
        "\n",
        "\n",
        "### ggg Using Built-In Distribution Functions zzz {#sec-like-r}"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "For many common distributions, R has built in functions to compute the values of pmf's for many discrete random variables and pdf's for continuous random variables. For Poisson distributions, the function `dpois(x, lambda)` calculates the value of $f(x; \\lambda) = \\frac{\\lambda^{x} e^{-\\lambda}}{x!}$. \n",
        "\n",
        "- Therefore, we can use the `dpois(x, lam)` function in place of the expression `lam^x * exp(-lam)/factorial(x)`.\n",
        "- The code cell below makes use of the `dpois(x, lam)` function and saves us the trouble of typing the formula out ourselves!\n",
        "- Run the code to evaluate the function at $\\lambda = 7$ to make sure the result is consistent with our previous functions.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "like <- function(lam){\n",
        "  pmf <- dpois(x, lam)\n",
        "  prod(pmf)\n",
        "}\n",
        "\n",
        "like(7)\n",
        "```\n",
        "\n",
        "## ggg Optimizing the Likelihood Function in R zzz {#sec-opt-r}\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In [Question 3] we used methods from calculus to find the value of $\\theta$ that maximizes the likelihood function $L(\\theta)$. We can check those results using the command `optimize(function, interval, maximum = TRUE)`.\n",
        "\n",
        "- `function` is the name of the function where we stored the likelihood function.\n",
        "- `interval` is the interval of parameter values over which we maximize the likelihood function.\n",
        "  - Using `c(0,100)` means we will find the maximum of $L(\\theta)$ over $0 < \\lambda < 100$.\n",
        "  - Based on the values in our sample, we can narrow the interval to save a little computing time.\n",
        "- `maximum = TRUE` option means `optimize()` will identify the maximum of the function.\n",
        "  - Note the default for `optimize()` is to find the minimum value.\n",
        "- Run the command below to calculate $\\hat{\\lambda}_{\\rm{MLE}}$ for the slot machine example.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "optimize(like, c(0,100), maximum = TRUE)\n",
        "```\n",
        "\n",
        "# ggg A First Look at Properties of MLE's zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The random sample $x_1=9$, $x_2=8$ , $x_3=6$, and $x_4=5$  picked from $X \\sim \\mbox{Pois}(\\lambda)$ gave $\\hat{\\lambda}_{\\rm{MLE}} = 7$. If we had picked another random sample $n=4$ from the population $X \\sim \\mbox{Pois}(\\lambda)$, how much will our estimate for $\\hat{\\lambda}_{\\rm{MLE}}$ change? Some desirable properties for the distribution of $\\hat{\\lambda}_{\\rm{MLE}}$ values from different random samples would be:\n",
        "\n",
        "- We would like the estimates to be <span style=\"color:dodgerblue\">**unbiased**</span>. \n",
        "  - We would like, on average, $\\hat{\\lambda}_{\\rm{MLE}}$ to equal the actual value of $\\lambda$.\n",
        "  - In other words, we would like $E \\left(\\hat{\\lambda}_{\\rm{MLE}} \\right)=\\lambda$.\n",
        "- Hopefully the values of $\\hat{\\lambda}_{\\rm{MLE}}$ <span style=\"color:dodgerblue\">**do not vary very**</span> much from sample to sample.\n",
        "  - One way to measure this is to consider $\\mbox{Var} \\left( \\hat{\\lambda}_{\\rm{MLE}} \\right)$.\n",
        "  - The smaller $\\mbox{Var} \\left( \\hat{\\lambda}_{\\rm{MLE}} \\right)$ the better.\n",
        "  - The variance, $\\mbox{Var} \\left( \\hat{\\lambda}_{\\rm{MLE}} \\right)$, is called the <span style=\"color:dodgerblue\">**efficiency**</span> of the $\\hat{\\lambda}_{\\rm{MLE}}$\n",
        "- <span style=\"color:dodgerblue\">**We hope the estimates make practical sense**</span>. \n",
        "\n",
        "## ggg Question 4 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If population $X \\sim \\mbox{Pois}(\\lambda)$ is the number of jackpot payouts a randomly selected slot machine has in one week:\n",
        "\n",
        "- What is the practical interpretation of the value of $\\lambda$?\n",
        "- If we pick a random sample of 4 slot machines and find $x_1=9$, $x_2=8$ , $x_3=6$, and $x_4=5$, explain why an estimate  $\\hat{\\lambda}_{\\rm{MLE}} = 7$ makes practical sense.\n",
        "\n",
        "\n",
        "### ggg Solution to Question 4 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "##  ggg Picking Another Random Sample zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random sample $x_1=9$, $x_2=8$ , $x_3=6$, and $x_4=5$  picked from $X \\sim \\mbox{Pois}(\\lambda)$ gave $\\hat{\\lambda}_{\\rm{MLE}} = 7$. The actual value of $\\lambda$ we revealed the `true.mean` we used was $\\lambda = 8$. Below we simulate picking another random sample of $n=4$ values from the same population, $X \\sim \\mbox{Pois}(8)$. Then we will compute $\\hat{\\lambda}_{\\rm{MLE}} = 7$ for this sample and see if we can start to pick up on a pattern.\n",
        "\n",
        "- Run the code cell below to generate a new random sample stored in `new.x`.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "set.seed(012)  # fixes randomization\n",
        "\n",
        "new.x <- rpois(4, 8)  # pick another random sample n=4 from Pois(8)\n",
        "new.x  # print results\n",
        "```\n",
        "\n",
        "\n",
        "The new sample is $x_1=4$, $x_2=11$ , $x_3=13$, and $x_4=6$. \n",
        "\n",
        "- Run the code cell to compute the value of $\\hat{\\lambda}_{\\rm{MLE}}$ for this new sample.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "new.like <- function(lam){\n",
        "  new.pmf <- dpois(new.x, lam)\n",
        "  prod(new.pmf)\n",
        "}\n",
        "\n",
        "optimize(new.like, c(0,100), maximum = TRUE)\n",
        "```\n",
        "\n",
        "### ggg Comparing Estimates zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Let's compare the two random samples and their corresponding values for the MLE estimate.\n",
        "\n",
        "| Sample | Value of MLE\n",
        "|--------|--------------|\n",
        "| $x_1=9$, $x_2=8$ , $x_3=6$, $x_4=5$  | $7$ |\n",
        "| $x_1=4$, $x_2=11$ , $x_3=13$, $x_4=6$ | $8.5$ |\n",
        "\n",
        "- Neither gives the correct value for $\\lambda$ which is actually 8.\n",
        "  - One estimate is too small and the other is too large.\n",
        "- We hope if we average all such MLE estimates together, we get the actual value $8$.\n",
        "- We have some sense of the variation, but generating many (10,000) random samples and looking at the distribution of many more MLE estimates will tell us more information about the variability.\n",
        "\n",
        "\n",
        "\n",
        "## ggg Analyzing a Distribution of MLE's zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The for loop in the code cell below generates a distribution of MLE's for $\\lambda$ based on 10,000 random samples size $n=4$ picked from $X \\sim \\mbox{Pois}(8)$. Inside the for loop we:\n",
        "\n",
        "- Pick a random sample size $n=4$ stored in `temp.x`.\n",
        "- Calculate the MLE based on `temp.x` that we store in the vector `pois.mle`.\n",
        "\n",
        "Then we plot a histogram to display `pois.mle`, the distribution of MLE's from the 10,000 random samples each size $n=4$\n",
        "\n",
        "- Run the code cell below to generate and plot a distribution of MLE's.\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "pois.mle <- numeric(10000)\n",
        "\n",
        "for (i in 1:10000)\n",
        "{\n",
        "  temp.x <- rpois(4, 8)  # given random sample\n",
        "  like.pois <- function(lam){  # define likelihood function\n",
        "    pmf.pois <- dpois(temp.x, lam)  \n",
        "    prod(pmf.pois)  \n",
        "}\n",
        "  pois.mle[i] <- optimize(like.pois, c(0,100), maximum = TRUE)$maximum  # find max of likelihood function\n",
        "}\n",
        "\n",
        "hist(pois.mle, \n",
        "     breaks = 20,\n",
        "     xlab = \"MLE\",\n",
        "     main = \"Dist. of MLE's for Poisson Dist\")\n",
        "abline(v = 8, col = \"blue\", lwd = 2)  # plot at actual value of lambda\n",
        "```\n",
        "\n",
        "\n",
        "## ggg Question 5 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Calculate the mean and variance of the distribution of MLE's stored in `mle.pois` and interpret the results. How would you describe the shape of the distribution? What would you expect to happen to the distribution as $n$ gets larger?\n",
        "\n",
        "\n",
        "### ggg Solution to Question 5 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{r}\n",
        "# use code cell to answer questions above\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "# ggg Practice: Finding Formulas for $L(\\theta)$ zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ggg Question 6 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Give a formula the likelihood function given the sample $(x_1, x_2, x_3, x_4) = (1,3,3,2)$ is randomly selected from  $X \\sim \\mbox{Binom}(3,p)$.\n",
        "\n",
        "\n",
        "### ggg Solution to Question 6 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "## ggg Question 7 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Give a formula the likelihood function given the sample $x_1, x_2, x_3, \\ldots, x_n$ is randomly selected from  $X \\sim \\mbox{Exp}(\\lambda)$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ggg Solution to Question 7 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ggg Practice: Maximizing the Likelihood Function zzz\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ggg Question 8 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Using your answer from [Question 6], find the MLE for $p$ when $(x_1, x_2, x_3, x_4) = (1,3,3,2)$ comes from $X \\sim \\mbox{Binom}(3,p)$.\n",
        "\n",
        "\n",
        "\n",
        "### ggg Solution to Question 8 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "## ggg Steps for Finding MLE zzz "
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Steps for finding MLE, $\\hat{\\theta}_{\\rm MLE}$:\n",
        "\n",
        "1. Find a formula the likelihood function.\n",
        "\n",
        "$$L(\\theta \\mid x_1, x_2, \\ldots , x_n) = f(x_1; \\theta) f(x_2; \\theta) \\ldots f(x_n; \\theta) = \\prod_{i=1}^n f(x_i; \\theta)$$\n",
        "\n",
        "2. Maximize the likelihood function.\n",
        "    a. Take the derivative of $L$ with respect to $\\theta$\n",
        "    b. Find critical points of $L$ where $\\frac{dL}{d\\theta}=0$ (or is undefined).\n",
        "    c. Evaluate $L$ at each critical point and identify the MLE.\n",
        "\n",
        "\n",
        "3. Check your work!\n",
        "\n",
        "## ggg Plotting the Likelihood Function for Question 8 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the code cell below will generate a plot of the likelihood function from [Question 8]. We should verify the maximum of the graph coincides with our answer to [Question 8]. There is nothing to edit in the code cell below.\n",
        "\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "p <- seq(0, 1, 0.01)  # values of p on x-axis\n",
        "like.binom <- 9 * p^9 * (1-p)^3  # values of L(p)\n",
        "cv <- 9 * (0.75)^9 * (1-0.75)^3\n",
        "\n",
        "plot(p, like.binom,  # plot p and likelihood on x and y axes\n",
        "     type = \"l\",  # connect plotted points with a curve\n",
        "     ylab = \"L(p)\",  # y-axis label\n",
        "     xlab = \"p\",  # x-axis label\n",
        "     main = \"Plot of Likelihood Function\")  # main label\n",
        "\n",
        "points(x = 0.75, y = cv, cex = 2, pch = 20, col = \"tomato\")  # point at max\n",
        "\n",
        "axis(1, at=c(0.75), col.axis = \"tomato\", pos=0)  # marking MLE estimate\n",
        "abline(v = 0.75, col = \"tomato\", lwd = 2, lty = 2)  # marking MLE estimate\n",
        "```\n",
        "\n",
        "\n",
        "## ggg Question 9 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Recall the sample from [Question 6]. Complete the code cell below to build a formula for the likelihood function and find the value of $\\hat{p}_{\\rm{MLE}}$. Run the completed code cell to check your answer in [Question 8].\n",
        "\n",
        "- *Hint: See earlier code for [constructing the likelihood function](#sec-like-r) and [finding the maximum](#sec-opt-r).*\n",
        "- *Hint: When considering the interval option for `optimize()`, keep in mind we are estimating the value of a proportion, $p$.*\n",
        "\n",
        "\n",
        "### ggg Solution to Question 9 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace each of the four `??` in the code cell below with appropriate code. Then run the completed code to compute the MLE estimate $\\hat{p}_{\\rm{MLE}}$ for the sample `x` picked from $X \\sim \\mbox{Binom}(3,p)$.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: false\n",
        "x <- c(1, 3, 3, 2)  # given random sample\n",
        "\n",
        "like.binom <- function(p){\n",
        "  pmf.binom <- ??  # replace ??\n",
        "  prod(??)  # replace ??\n",
        "}\n",
        "\n",
        "optimize(??, ??, maximum = TRUE)  # replace both ??\n",
        "```\n",
        "\n",
        "\n",
        "# ggg Using the Log-Likelihood Function zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Logarithmic functions such as $y = \\ln{x}$  are increasing functions. The larger the input $x$, the larger the output $y = \\ln{x}$ becomes. Thus, the value of $\\theta$ that gives the maximum value of $L(\\theta)$ will also correspond to the value of $\\theta$ that gives the maximum value of the function $y = \\ln{(L(\\theta))}$, and vice versa\n",
        "\n",
        "> <span style=\"color:dodgerblue\">The value of $\\theta$ that maximizes functions $y=\\ln{(L(\\theta}))$ is the value of $\\theta$ that maximizes $L(\\theta)$.</span>\n",
        "\n",
        "We call the the natural log of the likelihood function, $\\color{dodgerblue}{y=\\ln{(L(\\theta}))}$, the <span style=\"color:dodgerblue\">**log-likelihood function**</span>.\n",
        "\n",
        ":::{.callout-caution}\n",
        "In statistics, the term \"log\" usually means \"natural log\". The notation $\\log{()}$ is often used to denote a natural log instead of using $\\ln{()}$. This can be confusing since you may have previously learned $\\log{()}$ implies \"log base 10\". Similarly, in R\n",
        "\n",
        "- The function `log(x)` is the natural log of x. \n",
        "- The function `log10(x)` is the log base 10 of x.\n",
        ":::\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| label: fig-charts\n",
        "#| fig-cap: \"Comparing Maxima\"\n",
        "#| fig-subcap: \n",
        "#|   - \"Maximum of Likelihood\"\n",
        "#|   - \"Maximum of Log-Likelihood\"\n",
        "#| layout-ncol: 2\n",
        "#| eval: true\n",
        "#| echo: false\n",
        "x <- seq(from=0, to=40, by=0.1)\n",
        "y <- 12 * x * exp(-0.2*x)\n",
        "cv <- 12 * 5 * exp(-0.2*5)\n",
        "\n",
        "plot(x, y, \n",
        "     type=\"l\", \n",
        "     lwd = 2, \n",
        "     col = \"dodgerblue\",\n",
        "     xlab = \"theta\",\n",
        "     ylab = \"L(theta)\",\n",
        "     main = \"Max of Likelihood\",\n",
        "     cex.lab=2, cex.axis=2, cex.main=2)\n",
        "points(x = 5, y = cv, cex = 2, pch = 20, col = \"tomato\")  # point at max\n",
        "axis(1, at=c(5), col.axis = \"tomato\", pos=0, cex.axis=2)  # marking MLE estimate\n",
        "abline(v = 5, col = \"tomato\", lwd = 2, lty = 2)  # marking MLE estimate\n",
        "\n",
        "plot(x, log(y), \n",
        "     type=\"l\", \n",
        "     lwd = 2, \n",
        "     col = \"dodgerblue\",\n",
        "     xlab = \"theta\",\n",
        "     ylab = \"ln(L(theta))\",\n",
        "     main = \"Max of Log-Likelihood\",\n",
        "    cex.lab=2, cex.axis=2, cex.main=2)\n",
        "points(x = 5, y = log(cv), cex = 2, pch = 20, col = \"tomato\")  # point at max\n",
        "axis(1, at=c(5), col.axis = \"tomato\", pos=-2, cex.axis=2)  # marking MLE estimate\n",
        "abline(v = 5, col = \"tomato\", lwd = 2, lty = 2)  # marking MLE estimate\n",
        "```\n",
        "\n",
        "\n",
        "## ggg Why Maximize $y=\\ln{(L(\\theta}))$ Instead of $L(\\theta)$? zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the likelihood function from [Question 7],\n",
        "\n",
        "$$L({\\color{tomato}\\lambda}) = {\\color{\\tomato}\\lambda}^n e^{- {\\color{tomato}\\lambda} \\sum_i x_i}.$$\n",
        "To find the critical values, we first need to find an expression for the derivative $\\frac{d L}{d \\lambda}$. \n",
        "\n",
        "- We need to apply the product rule.\n",
        "- We need to apply the chain rule to compute the derivative of $e^{- {\\color{tomato}\\lambda} \\sum_i x_i}$.\n",
        "- After finding an expression for the derivative, we would then need to solve a complicated equation.\n",
        "- <span style=\"color:dodgerblue\">**We can use key properties of the natural log to help make the differentiation easier!**</span> \n",
        "\n",
        "## ggg Useful Properties of the Natural Log zzz {#sec-log-prop}"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The four properties of natural logs listed below will be helpful to recall when working with log-likelihood functions.\n",
        "\n",
        "1. $\\ln{(A \\cdot B)} = \\ln{A} + \\ln{B}$\n",
        "2. $\\ln{\\left( \\frac{A}{B} \\right)} = \\ln{A} - \\ln{B}$\n",
        "3. $\\ln{(A^k)} = k \\ln{A}$\n",
        "4. $\\ln{e^k} = k$\n",
        "\n",
        "\n",
        "Likelihood functions are by definition a product of functions and often involve $e$. Taking the natural log of the likelihood function converts a product to a sum. <span style=\"color:dodgerblue\">**It is much easier to take the derivative of sums than products!**</span>  \n",
        "\n",
        "\n",
        "## ggg Question 10 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Give a simplified expression for the log-likelihood function corresponding to the likelihood function from the exponential distribution in [Question 7],\n",
        "\n",
        "$$L({\\color{tomato}\\lambda}) = {\\color{\\tomato}\\lambda}^n e^{- {\\color{tomato}\\lambda} \\sum_i x_i}.$$\n",
        "\n",
        "\n",
        "### ggg Solution to Question 10 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "# ggg Steps for Finding MLE Using a Log-Likelihood Function zzz \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Steps for finding MLE, $\\hat{\\theta}_{\\rm MLE}$, using a log-likelihood function:\n",
        "\n",
        "1. Find a formula the likelihood function.\n",
        "\n",
        "$$L(\\theta \\mid x_1, x_2, \\ldots , x_n) = f(x_1; \\theta) f(x_2; \\theta) \\ldots f(x_n; \\theta) = \\prod_{i=1}^n f(x_i; \\theta)$$\n",
        "2. Apply the natural log to $L(\\theta)$ to derive the log-likelihood function $y = \\ln{(L(\\theta))}$. Simplify using [properties of the natural log](#sec-log-prop) before moving to the next step.\n",
        "\n",
        "3. Maximize the log-likelihood function.\n",
        "    a. Take the derivative of $y=\\ln{(L(\\theta))}$ with respect to $\\theta$\n",
        "    b. Find critical points of the log-likelihood function  where $\\frac{dy}{d\\theta}=0$ (or is undefined).\n",
        "    c. Evaluate the log-likelihood function $y=\\ln{(L(\\theta))}$ at each critical point and identify the MLE.\n",
        "\n",
        "4. Check your work!\n",
        "\n",
        "\n",
        "## ggg Question 11 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "Find a general formula for the MLE of $\\lambda$ when $x_1, x_2, x_3, \\ldots, x_n$ comes from $X \\sim \\mbox{Exp}(\\lambda)$. Your answer will depend on the $x_i$'s.\n",
        "\n",
        "- *Hint: Maximize the log-likelihood function from [Question 10].*\n",
        "- *Hint: Be sure you simplify the log-likelihood before taking the derivative.*\n",
        "- *Hint: Recall $\\lambda$ is the variable when differentiating, and treat each $x_i$ as a constant.*\n",
        "\n",
        "\n",
        "## ggg Solution to Question 11 zzz\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "## ggg Analytic Results zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "In [Question 11], we found a general formula for $\\hat{\\lambda}_{\\rm{MLE}}$, the MLE of exponential distributions in general. We cannot use R to numerically check our analytic results since our result is a formula that depends on the values of the $x_i$'s. We can test our formula on with many different random samples and check to make sure our formula gives consistent answers with numeric solutions in R. Using calculus to derive the general formula for $\\hat{\\lambda}_{\\rm{MLE}}$ in [Question 11] is incredibly convenient since now we have a \"shortcut\" formula that we can use for finding MLE estimates for any random sample from an exponential distributions. \n",
        "\n",
        "> <span style=\"color:dodgerblue\">It is really important to practice deriving general formulas for MLE estimates even though we can use R to numerically solve some MLE examples.</span>\n",
        "\n",
        "## ggg Question12 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find a general formula for the MLE of $\\lambda$ when $x_1, x_2, x_3, \\ldots, x_n$ comes from $X \\sim \\mbox{Pois}(\\lambda)$. Your answer will depend on the $x_i$'s.\n",
        "\n",
        "### ggg Solution to Question 12 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## ggg Question 13 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose a random variable with $X_1=5$, $X_2=9$, $X_3=9$, and $X_4=10$ is drawn from a distribution with pdf\n",
        "\n",
        "$$f(x; \\theta) = \\frac{\\theta}{2\\sqrt{x}}e^{-\\theta \\sqrt{x}}, \\quad \\mbox{where x $>0$}.$$\n",
        "\n",
        "Find an MLE for $\\theta$.\n",
        "\n",
        "\n",
        "### ggg Solution to Question 13 zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "## ggg Question 13 zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the random sample of $n=40$ values picked from a geometric distribution $X \\sim \\mbox{Geom}(p)$ that are stored in the vector `x.geom`. Note the proportion `true.p` is unknown for now. \n",
        "\n",
        "\n",
        "- Run the code cell below to generate a random value for `true.p` (which is hidden) and create `x.geom` which is printed to the screen.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: true\n",
        "set.seed(117)  # fixes randomization of true.p and x.geom\n",
        "true.p <- sample(seq(0.1, 0.9, 0.1), size=1)  # true.p hidden for now\n",
        "\n",
        "x.geom <- rgeom(40, true.p)  # generate a random sample n=40  \n",
        "x.geom\n",
        "```\n",
        "\n",
        "\n",
        "### ggg Question 13a zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Based on the sample stored in `x.geom` in the previous code cell, find the MLE estimate for $\\hat{p}_{\\rm{MLE}}$. \n",
        "\n",
        "- *Hint: Use the partially complete R code cell below to help!*\n",
        "\n",
        "#### Solution to Question 13a\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace each of the four `??` in the code cell below with appropriate code. Then run the completed code to compute the MLE estimate $\\hat{p}_{\\rm{MLE}}$ for the sample (size $n=40)$ `x.geom` randomly selected from $X \\sim \\mbox{Geom}(p)$.\n",
        "\n",
        "```{r}\n",
        "like.geom <- function(p){\n",
        "  pmf.geom <- ??  # replace ??\n",
        "  prod(??)  # replace ??\n",
        "}\n",
        "\n",
        "\n",
        "optimize(??, ??, maximum = TRUE)  # replace both ??\n",
        "```\n",
        "\n",
        "\n",
        "### ggg Question 13b zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Complete the partially completed code cell below to generate a plot of a distribution of MLE's for $\\hat{p}_{\\rm{MLE}}$ based on 10,000 randomly selected samples from $X \\sim \\mbox{Geom}(p)$.\n",
        "\n",
        "\n",
        "#### ggg Solution to Question 13b zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace each of the four `??` in the code cell below with appropriate code. Then run the completed code to create and plot a  distribution of MLE's for samples size $n=40$ from $X \\sim \\mbox{Geom}(p)$.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# #| eval: false\n",
        "mle.geom <- numeric(10000)\n",
        "\n",
        "for (i in 1:10000)\n",
        "{\n",
        "  x.temp <- rgeom(40, true.p)  # pick random sample size n=40\n",
        "  geom.like <- function(p){\n",
        "    geom.pmf <- ??  # replace ??\n",
        "    prod(??)  # replace ??\n",
        "}\n",
        "  mle.geom[i] <- optimize(??, ??, maximum = TRUE)$maximum  # replace both ??\n",
        "}\n",
        "\n",
        "hist(mle.geom, \n",
        "     breaks = 20,\n",
        "     xlab = \"MLE\",\n",
        "     main = \"Dist. of MLE's\")\n",
        "abline(v = true.p, col = \"dodgerblue\", lwd = 2)  # actual value of p\n",
        "abline(v = true.p, col = \"tomato\", lwd = 2)  # expected value of MLE\n",
        "```\n",
        "\n",
        "\n",
        "### ggg Question 13c zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Based on the distribution of MLE's in [Question 13b], do you believe the estimator $\\hat{p}_{\\rm{MLE}}$ is unbiased or biased? Explain why or why not.\n",
        "\n",
        "\n",
        "### ggg Solution to Question 13c zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "\n",
        "\n",
        "# ggg Summary of Results from Common Distributions zzz"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        " So far we have observed:\n",
        "\n",
        "- **Poisson distributions:** $X \\sim \\mbox{Pois}(\\lambda)$ have  $\\displaystyle \\hat{\\lambda}_{\\rm MLE} = \\bar{x}$\n",
        "- **Binomial distributions:** $X \\sim \\mbox{Binom}(n,p)$ have $\\displaystyle \\hat{p}_{\\rm MLE} = \\hat{p}$.\n",
        "- **Exponential distributions:** $X \\sim \\mbox{Exp}(\\lambda)$ have $\\displaystyle \\hat{\\lambda}_{\\rm MLE} = \\frac{1}{\\bar{x}}$.\n",
        "- **Geometric distributions:** $X \\sim \\mbox{Geom}(p)$ have $\\displaystyle \\hat{p}_{\\rm MLE} = \\frac{1}{\\bar{x}}$.\n",
        "\n",
        "For **normal distributions** $X \\sim N(\\mu, \\sigma)$,  the maximum likelihood estimates of $\\mu$ and $\\theta$ are\n",
        "$$\\hat{\\mu}_{\\rm{MLE}} = \\frac{1}{n} \\sum_{i=1}^n x_i = \\bar{x} \\quad \\mbox{ and } \\quad \\hat{\\sigma}_{\\rm{MLE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2}.$$\n",
        "\n",
        "- See [this post](https://towardsdatascience.com/maximum-likelihood-estimation-explained-normal-distribution-6207b322e47f) for a derivation of the MLE formulas for $\\hat{\\mu}_{\\rm{MLE}}$ and $\\hat{\\sigma}_{\\rm{MLE}}$.\n",
        "- [These materials from Penn State](https://online.stat.psu.edu/stat415/lesson/1/1.2) also explain how to derive the MLE formulas for $\\hat{\\mu}_{\\rm{MLE}}$ and $\\hat{\\sigma}_{\\rm{MLE}}$.\n",
        "\n",
        "# ggg Recap of Maximum Likelihood Estimates zzz\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- <span style=\"color:dodgerblue\">**MLE's give reasonable estimates that make sense!**</span> \n",
        "- MLE's are often good estimators since they satisfy several nice properties\n",
        "  - <span style=\"color:dodgerblue\">*Consistency*</span>:  As we get more data (sample size goes to infinity), the estimator becomes more and more accurate and converges to the actual value of $\\theta$.\n",
        "  - <span style=\"color:dodgerblue\">*Normality*</span>: As we get more data, the distribution of MLE's converge to a normal distribution.\n",
        "  - <span style=\"color:dodgerblue\">*Efficiency*</span>: They have the smallest possible variance for a consistent estimator.\n",
        "-  <span style=\"color:tomato\">**The downside is finding MLE's are not always easy (or possible).**</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "![Creative Commons License](https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png) <nbsp>\n",
        "\n",
        "*Statistical Methods: Exploring the Uncertain* by [Adam Spiegler](https://github.com/CU-Denver-MathStats-OER/Statistical-Theory) is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}